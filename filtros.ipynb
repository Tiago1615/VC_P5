{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Paquetes necesarios\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para superponer imágenes con canal alfa\n",
    "def overlay_image_alpha(img, overlay, position, alpha_mask):\n",
    "    x, y = position\n",
    "    h, w = overlay.shape[:2]\n",
    "\n",
    "    # Recorte de las coordenadas para asegurar que no se salga del frame\n",
    "    if x < 0:\n",
    "        overlay = overlay[:, -x:]\n",
    "        alpha_mask = alpha_mask[:, -x:]\n",
    "        w += x\n",
    "        x = 0\n",
    "    if y < 0:\n",
    "        overlay = overlay[-y:, :]\n",
    "        alpha_mask = alpha_mask[-y:, :]\n",
    "        h += y\n",
    "        y = 0\n",
    "    if x + w > img.shape[1]:\n",
    "        overlay = overlay[:, :img.shape[1] - x]\n",
    "        alpha_mask = alpha_mask[:, :img.shape[1] - x]\n",
    "        w = img.shape[1] - x\n",
    "    if y + h > img.shape[0]:\n",
    "        overlay = overlay[:img.shape[0] - y, :]\n",
    "        alpha_mask = alpha_mask[:img.shape[0] - y, :]\n",
    "        h = img.shape[0] - y\n",
    "\n",
    "    # Crear un fondo y sobreponer con la máscara alfa\n",
    "    img_crop = img[y:y+h, x:x+w]\n",
    "    img_crop[:] = img_crop * (1 - alpha_mask[:, :, np.newaxis] / 255.0) + overlay * (alpha_mask[:, :, np.newaxis] / 255.0)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Función para cargar fotogramas de un GIF\n",
    "def load_gif_frames(gif_path):\n",
    "    pil_gif = Image.open(gif_path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            frame = pil_gif.convert(\"RGBA\")\n",
    "            frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGBA2BGRA)\n",
    "            frames.append(frame)\n",
    "            pil_gif.seek(pil_gif.tell() + 1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error en detección o análisis de emociones: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15404\\3907352144.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moverlay_image_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhair_resized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhair_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhair_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhair_alpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error en detección o análisis de emociones:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[1;34m\"antispoof_score\"\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mof\u001b[0m \u001b[0mantispoofing\u001b[0m \u001b[0manalyze\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mjust\u001b[0m \u001b[0mavailable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0monly\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0manti_spoofing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \"\"\"\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m     return detection.extract_faces(\n\u001b[0m\u001b[0;32m    550\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mdetector_backend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector_backend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[0menforce_detection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menforce_detection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\deepface\\modules\\detection.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdetector_backend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"skip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mface_objs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDetectedFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacial_area\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_region\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         face_objs = detect_faces(\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mdetector_backend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector_backend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\deepface\\modules\\detection.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(detector_backend, img, align, expand_percentage)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Color of the border (black)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         )\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;31m# find facial areas of given image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[0mfacial_areas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfacial_area\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfacial_areas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\deepface\\models\\face_detection\\MtCnn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# mtcnn expects RGB but OpenCV read BGR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdetections\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, image, fit_to_image, limit_boundaries_landmarks, box_format, output_type, postprocess, batch_stack_justification, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;31m# Process images through each stage (PNet, RNet, ONet)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                     \u001b[0mbboxes_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbboxes_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_normalized\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_oshapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_oshapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# No faces found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[0mbboxes_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mpad_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\mtcnn\\stages\\stage_pnet.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, images_normalized, images_oshapes, min_face_size, min_size, scale_factor, threshold_pnet, nms_pnet1, nms_pnet2, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mscales_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_scales\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# 3. Get proposals bounding boxes and confidence from the model (PNet)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mpnet_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscales_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# 4. Generate bounding boxes per scale group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mbboxes_proposals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgenerate_bounding_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_pnet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpnet_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\mtcnn\\stages\\stage_pnet.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     def __call__(self, images_normalized, images_oshapes, min_face_size=20, min_size=12, scale_factor=0.709,\n\u001b[0m\u001b[0;32m     93\u001b[0m                  threshold_pnet=0.6, nms_pnet1=0.5, nms_pnet2=0.7, **kwargs):\n\u001b[0;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m     95\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPNet\u001b[0m \u001b[0mstage\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mimages\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[0mbounding\u001b[0m \u001b[0mbox\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 ):\n\u001b[1;32m-> 1142\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\mtcnn\\network\\pnet.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprelu2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# Third conv block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprelu3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mbbox_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 ):\n\u001b[1;32m-> 1142\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\layers\\activation\\prelu.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mneg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgome\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   7753\u001b[0m         _ctx, \"Neg\", name, x)\n\u001b[0;32m   7754\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7755\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7756\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7757\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7758\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7759\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7760\u001b[0m       _result = _dispatcher_for_neg(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scouter = cv2.imread('scouter.png', cv2.IMREAD_UNCHANGED)\n",
    "aura_index = 0\n",
    "\n",
    "hair = cv2.imread('goku-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "aura_frames = load_gif_frames('aura.gif')\n",
    "aura_frame_count = len(aura_frames)\n",
    "frame_count = 0\n",
    "changed = 0\n",
    "\n",
    "# Captura de video en tiempo real\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height =int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "out = cv2.VideoWriter(\"kakaroto_video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Detección de rostros\n",
    "        faces = DeepFace.extract_faces(frame, detector_backend='mtcnn')\n",
    "\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['facial_area']['x'], face['facial_area']['y'], face['facial_area']['w'], face['facial_area']['h']\n",
    "            face_width = w\n",
    "            face_height = h\n",
    "\n",
    "            # Análisis de emoción\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "            analysis = DeepFace.analyze(face_img, actions=['emotion'], enforce_detection=False)\n",
    "            emotion = analysis[0]['dominant_emotion']\n",
    "\n",
    "            # Activar efectos si la emoción es enfado\n",
    "            \n",
    "            scouter_resized = cv2.resize(scouter, (int(face_width * 0.5), int(face_height * 0.3)))\n",
    "            scouter_alpha = scouter_resized[:, :, 3]\n",
    "\n",
    "            \n",
    "            eye_x = face['facial_area']['right_eye'][0] - w // 3\n",
    "            eye_y = face['facial_area']['right_eye'][1] - scouter_resized.shape[1] // 3\n",
    "\n",
    "            if emotion == 'angry':\n",
    "                hair_resized = cv2.resize(hair, (face_width * 3, face_height * 3))\n",
    "                hair_alpha = hair_resized[:, :, 3]\n",
    "                hair_x = x + face_width // 2 - hair_resized.shape[1] // 2\n",
    "                hair_y = y - int(hair_resized.shape[0] * 0.7)\n",
    "\n",
    "                aura_frame = aura_frames[aura_index]\n",
    "                aura_resized = cv2.resize(aura_frame, (frame.shape[0] * 2, frame.shape[1] * 2))\n",
    "                aura_alpha = aura_resized[:, :, 3]\n",
    "\n",
    "                aura_x = x + face_width // 2 - aura_resized.shape[1] // 2\n",
    "                aura_y = round(y - frame.shape[1] * 1.05)\n",
    "\n",
    "                if (frame_count < 10):\n",
    "                    if (changed == 0):\n",
    "                        aura_frames = load_gif_frames('aura.gif')\n",
    "                        aura_frame_count = len(aura_frames)\n",
    "                        changed += 1\n",
    "                    hair = cv2.imread('saiyan-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "                elif (frame_count < 20):\n",
    "                    if (changed == 1):\n",
    "                        aura_frames = load_gif_frames('aura-god.gif')\n",
    "                        aura_frame_count = len(aura_frames)\n",
    "                        changed += 1\n",
    "                    hair = cv2.imread('god-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "                elif (frame_count < 30):\n",
    "                    if (changed == 2):\n",
    "                        aura_frames = load_gif_frames('aura-blue.gif')\n",
    "                        aura_frame_count = len(aura_frames)\n",
    "                        changed += 1\n",
    "                    hair = cv2.imread('blue-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "                else:\n",
    "                    if (changed == 3):\n",
    "                        aura_frames = load_gif_frames('aura-instinct.gif')\n",
    "                        aura_frame_count = len(aura_frames)\n",
    "                        changed += 1\n",
    "                    hair = cv2.imread('instinct-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                # Superposición de efectos\n",
    "                frame = overlay_image_alpha(frame, aura_resized[:, :, :3], (aura_x, aura_y), aura_alpha)\n",
    "                frame = overlay_image_alpha(frame, scouter_resized[:, :, :3], (eye_x, eye_y), scouter_alpha)\n",
    "                frame = overlay_image_alpha(frame, hair_resized[:, :, :3], (hair_x, hair_y), hair_alpha)\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # Avanzar el índice de fotograma para animación\n",
    "                aura_index = (aura_index + 1) % aura_frame_count\n",
    "            else:\n",
    "                hair = cv2.imread('goku-hair.png', cv2.IMREAD_UNCHANGED)\n",
    "                hair_resized = cv2.resize(hair, (round(face_width * 2.6), face_height * 2))\n",
    "                hair_alpha = hair_resized[:, :, 3]\n",
    "                hair_x = x + face_width // 2 - hair_resized.shape[1] // 2\n",
    "                hair_y = y - int(hair_resized.shape[0] * 0.65)\n",
    "                frame = overlay_image_alpha(frame, scouter_resized[:, :, :3], (eye_x, eye_y), scouter_alpha)\n",
    "                frame = overlay_image_alpha(frame, hair_resized[:, :, :3], (hair_x, hair_y), hair_alpha)\n",
    "\n",
    "                \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error en detección o análisis de emociones:\", e)\n",
    "\n",
    "    out.write(frame)   \n",
    "\n",
    "    cv2.imshow(\"Filtro Saiyan\", frame)\n",
    "\n",
    "    # Cambiar de detector o salir\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Salir con ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
